# UCI ML Drug Review dataset
## Import kubeflow pipeline libraries
import pandas as pds
## Download Kaggle dataset
!pip install opendatasets
!pip install kaggle

def load_kaggle_dataset():
    """
    Downloads the kuc-hackathon-winter-2018 dataset from Kaggle and returns a Pandas dataframe containing the train and test data.
    Returns:
        df_train (pandas.DataFrame): The dataframe containing the training data.
        df_test (pandas.DataFrame): The dataframe containing the test data.
    """
    import os
    import pandas as pd
    from kaggle.api.kaggle_api_extended import KaggleApi
    
    # Set up the Kaggle API
    api = KaggleApi()
    api.authenticate() # Make sure you have a Kaggle API token and use api.authenticate()
    
    # Download the dataset
    api.dataset_download_files('jessicali9530/kuc-hackathon-winter-2018')
    
    # Unzip the downloaded files
    os.system('unzip -o kuc-hackathon-winter-2018.zip')
    
    # Read the files into Pandas dataframes
    df_train = pd.read_csv('drugsComTrain_raw.csv')
    df_test = pd.read_csv('drugsComTest_raw.csv')
    
    return df_train, df_test
df_train, df_test = load_kaggle_dataset()
print("Training data:\n", df_train.head())
print("\nTest data:\n", df_test.head())
Highlight any classes
import matplotlib.pyplot as plt
fig = plt.figure(figsize=(8,6))
df.groupby('drugName').Consumer_complaint_narrative.count().plot.bar(ylim=0)
plt.show()
## Preprocess Data
def preprocess_data(text):
    
    import re
    from bs4 import BeautifulSoup
    import nltk
    from nltk.corpus import stopwords
    from nltk.tokenize import word_tokenize
    from nltk.stem import PorterStemmer
    
    # Remove HTML tags
    text = BeautifulSoup(text, 'html.parser').get_text()

    # Remove non-alphabetic characters
    text = re.sub('[^a-zA-Z]', ' ', text)

    # Convert text to lowercase
    text = text.lower()

    # Tokenize text
    tokens = word_tokenize(text)

    # Remove English stopwords
    stop_words = set(stopwords.words('english'))
    tokens = [token for token in tokens if token not in stop_words]

    # Perform stemming
    stemmer = PorterStemmer()
    stemmed_tokens = [stemmer.stem(token) for token in tokens]

    # Join tokens back into a single string
    preprocessed_text = ' '.join(stemmed_tokens)

    return preprocessed_text
## EDA
import pandas as pd
import matplotlib.pyplot as plt

# Load data from CSV file into a Pandas data frame
df = pd.read_csv('kuc-hackathon-winter-2018/drugLibTrain_raw.csv')

# Group data by condition and count unique drugs
drugs_per_condition = df.groupby('condition')['drugName'].nunique()

# Plot histogram of drugs per condition
plt.hist(drugs_per_condition, bins=range(0, max(drugs_per_condition)+1, 1))
plt.xlabel('Number of drugs per condition')
plt.ylabel('Frequency')
plt.title('Distribution of drugs per condition')
plt.show()
